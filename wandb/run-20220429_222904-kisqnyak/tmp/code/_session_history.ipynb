{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f559c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from torchvision.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75621bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40eeda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efb6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from torchvision.models import *\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80722102",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = 0\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        idx += 1\n",
    "        labels[folder_dir] = idx\n",
    "        labels_r[idx] = folder_dir\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        for file_dir in os.listdir(f'./data/{folder_dir}/'):\n",
    "            img = cv2.imread(f'./data/{folder_dir}/{file_dir}')\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            img = img / 255.0\n",
    "            data.append([\n",
    "                img,\n",
    "                np.eye(labels[folder_dir],idx)[-1]\n",
    "            ])\n",
    "    np.random.shuffle(data)\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5b8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = 0\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        idx += 1\n",
    "        labels[folder_dir] = idx\n",
    "        labels_r[idx] = folder_dir\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        for file_dir in os.listdir(f'./data/{folder_dir}/'):\n",
    "            img = cv2.imread(f'./data/{folder_dir}/{file_dir}')\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            img = img / 255.0\n",
    "            data.append([\n",
    "                img,\n",
    "                np.eye(labels[folder_dir],idx)[-1]\n",
    "            ])\n",
    "    np.random.shuffle(data)\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=TEST_SIZE,shuffle=True)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).view(-1,3,56,56).float().to(device)\n",
    "    X_test = torch.from_numpy(np.array(X_test)).view(-1,3,56,56).float().to(device)\n",
    "    y_train = torch.from_numpy(np.array(y_train)).float().to(device)\n",
    "    y_test = torch.from_numpy(np.array(y_test)).float().to(device)\n",
    "    return X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ccca74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c9aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from torchvision.models import *\n",
    "from sklearn.model_selection import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ece0039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25\n",
    "device = 'cuda'\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab3134a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = 0\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        idx += 1\n",
    "        labels[folder_dir] = idx\n",
    "        labels_r[idx] = folder_dir\n",
    "    for folder_dir in tqdm(os.listdir('./data/')):\n",
    "        for file_dir in os.listdir(f'./data/{folder_dir}/'):\n",
    "            img = cv2.imread(f'./data/{folder_dir}/{file_dir}')\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            img = img / 255.0\n",
    "            data.append([\n",
    "                img,\n",
    "                np.eye(labels[folder_dir],idx)[-1]\n",
    "            ])\n",
    "    np.random.shuffle(data)\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=TEST_SIZE,shuffle=True)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).view(-1,3,56,56).float().to(device)\n",
    "    X_test = torch.from_numpy(np.array(X_test)).view(-1,3,56,56).float().to(device)\n",
    "    y_train = torch.from_numpy(np.array(y_train)).float().to(device)\n",
    "    y_test = torch.from_numpy(np.array(y_test)).float().to(device)\n",
    "    return X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c8b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe079f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from torchvision.models import *\n",
    "from sklearn.model_selection import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1dbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25\n",
    "device = 'cuda'\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a5c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = 0\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        idx += 1\n",
    "        labels[folder_dir] = idx\n",
    "        labels_r[idx] = folder_dir\n",
    "    for folder_dir in tqdm(os.listdir('./data/')):\n",
    "        for file_dir in os.listdir(f'./data/{folder_dir}/'):\n",
    "            img = cv2.imread(f'./data/{folder_dir}/{file_dir}')\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            img = img / 255.0\n",
    "            data.append([\n",
    "                img,\n",
    "                np.eye(labels[folder_dir],idx)[-1]\n",
    "            ])\n",
    "    np.random.shuffle(data)\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=TEST_SIZE,shuffle=True)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).view(-1,3,56,56).float().to(device)\n",
    "    X_test = torch.from_numpy(np.array(X_test)).view(-1,3,56,56).float().to(device)\n",
    "    y_train = torch.from_numpy(np.array(y_train)).float().to(device)\n",
    "    y_test = torch.from_numpy(np.array(y_test)).float().to(device)\n",
    "    return X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3af26de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a6fc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1886, 629, 1886, 629)"
     ]
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548c1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e9680e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,y_iter in zip(preds,y):\n",
    "        pred = torch.argmax(pred)\n",
    "        y_iter = torch.argmax(y_iter)\n",
    "        if pred == y_iter:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return round(correct/total,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "414d7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=1000, bias=True)"
     ]
    }
   ],
   "source": [
    "model = resnet18().to(device)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f13e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18().to(device)\n",
    "model.fc = Linear(512,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35dc0e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=36, bias=True)"
     ]
    }
   ],
   "source": [
    "model = resnet18().to(device)\n",
    "model.fc = Linear(512,idx)\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8e52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18().to(device)\n",
    "model.fc = Linear(512,idx)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cecac31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/indika/Sync/Programmer-RD-AI/Programming/Projects/Python/Artifical-Intelligence/PyTorch/CNN/American-Sign-Language-CNN/wandb/run-20220429_222904-kisqnyak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ranuga-d/American-Sign-Language-CNN/runs/kisqnyak\" target=\"_blank\">BaseLine resnet18</a></strong> to <a href=\"https://wandb.ai/ranuga-d/American-Sign-Language-CNN\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='BaseLine resnet18')\n",
    "wandb.watch(model)\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].float().view(-1,3,56,56).to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].float().to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    wandb.log({\n",
    "        'Accuracy Train':get_accuracy(model,X_train,y_train),\n",
    "        'Loss Train':get_loss(model,X_train,y_train,criterion),\n",
    "        'Accuracy Test':get_accuracy(model,X_test,y_test),\n",
    "        'Loss Test':get_loss(model,X_test,y_test,criterion),\n",
    "    })\n",
    "    model.train()\n",
    "wandb.watch(model)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03d937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from torchvision.transforms import *\n",
    "from torchvision.models import *\n",
    "from sklearn.model_selection import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99ab4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"American-Sign-Language-CNN\"\n",
    "TEST_SIZE = 0.25\n",
    "device = 'cuda'\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f924608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = {}\n",
    "    labels_r = {}\n",
    "    idx = 0\n",
    "    for folder_dir in os.listdir('./data/'):\n",
    "        idx += 1\n",
    "        labels[folder_dir] = idx\n",
    "        labels_r[idx] = folder_dir\n",
    "    for folder_dir in tqdm(os.listdir('./data/')):\n",
    "        for file_dir in os.listdir(f'./data/{folder_dir}/'):\n",
    "            img = cv2.imread(f'./data/{folder_dir}/{file_dir}')\n",
    "            img = cv2.resize(img,(56,56))\n",
    "            img = img / 255.0\n",
    "            data.append([\n",
    "                img,\n",
    "                np.eye(labels[folder_dir],idx)[-1]\n",
    "            ])\n",
    "    np.random.shuffle(data)\n",
    "    for d_iter in data:\n",
    "        X.append(d_iter[0])\n",
    "        y.append(d_iter[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=TEST_SIZE,shuffle=True)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).view(-1,3,56,56).float().to(device)\n",
    "    X_test = torch.from_numpy(np.array(X_test)).view(-1,3,56,56).float().to(device)\n",
    "    y_train = torch.from_numpy(np.array(y_train)).float().to(device)\n",
    "    y_test = torch.from_numpy(np.array(y_test)).float().to(device)\n",
    "    return X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09ceca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test,data,X,y,labels,labels_r,idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62918c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1886, 629, 1886, 629)"
     ]
    }
   ],
   "source": [
    "len(X_train),len(X_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e28db2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f80b2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,y_iter in zip(preds,y):\n",
    "        pred = torch.argmax(pred)\n",
    "        y_iter = torch.argmax(y_iter)\n",
    "        if pred == y_iter:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    return round(correct/total,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "215dc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18().to(device)\n",
    "model.fc = Linear(512,idx)\n",
    "model = model.to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "batch_size = 32\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64aa078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='BaseLine resnet18')\n",
    "wandb.watch(model)\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[idx:idx+batch_size].float().view(-1,3,56,56).to(device)\n",
    "        y_batch = y_train[idx:idx+batch_size].float().to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    wandb.log({\n",
    "        'Accuracy Train':get_accuracy(model,X_train,y_train),\n",
    "        'Loss Train':get_loss(model,X_train,y_train,criterion),\n",
    "        'Accuracy Test':get_accuracy(model,X_test,y_test),\n",
    "        'Loss Test':get_loss(model,X_test,y_test,criterion),\n",
    "    })\n",
    "    model.train()\n",
    "wandb.watch(model)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
